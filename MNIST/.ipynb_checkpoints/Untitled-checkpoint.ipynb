{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting t10k-images-idx3-ubyte.gz\n",
      "Extracting t10k-labels-idx1-ubyte.gz\n",
      "(50, 785)\n",
      "Extracting train-images-idx3-ubyte.gz\n",
      "Extracting train-labels-idx1-ubyte.gz\n",
      "33.395157 78.66619\n",
      "(200, 785)\n",
      "Learning Rate:0.01, Batch Size:20\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import gridspec\n",
    "import pickle\n",
    "import time\n",
    "import random\n",
    "from convnet import *\n",
    "from remtime import *\n",
    "\n",
    "#####################################################################################################################################\n",
    "################################################## ------ START HERE --------  ######################################################\n",
    "##################################### ---------- CONVOLUTIONAL NEURAL NETWORK ---------------  ######################################\n",
    "################ ----ARCHITECTURE PROPOSED : [INPUT - CONV1 - RELU - CONV2 - RELU- MAXPOOL - FC1 - OUT]---- #########################\n",
    "#####################################################################################################################################\n",
    "\n",
    "\n",
    "## Hyperparameters\n",
    "NUM_OUTPUT = 10\n",
    "LEARNING_RATE = 0.01\t#learning rate\n",
    "IMG_WIDTH = 28\n",
    "IMG_DEPTH = 1\n",
    "FILTER_SIZE=3\n",
    "NUM_FILT1 = 5\n",
    "NUM_FILT2 = 5\n",
    "BATCH_SIZE = 20\n",
    "NUM_EPOCHS = 2\t # number of iterations\n",
    "MU = 0.95\n",
    "\n",
    "PICKLE_FILE = 'output.pickle'\n",
    "# PICKLE_FILE = 'trained.pickle'\n",
    "\n",
    "\n",
    "\n",
    "## Data extracting\n",
    "m =10000\n",
    "X = extract_data('t10k-images-idx3-ubyte.gz', m, IMG_WIDTH)\n",
    "y_dash = extract_labels('t10k-labels-idx1-ubyte.gz', m).reshape(m,1)\n",
    "X-= int(np.mean(X))\n",
    "X/= int(np.std(X))\n",
    "test_data = np.hstack((X,y_dash))\n",
    "test_data = test_data[0,:]\n",
    "print(np.shape(test_data))\n",
    "\n",
    "\n",
    "m =50000\n",
    "X = extract_data('train-images-idx3-ubyte.gz', m, IMG_WIDTH)\n",
    "y_dash = extract_labels('train-labels-idx1-ubyte.gz', m).reshape(m,1)\n",
    "print (np.mean(X), np.std(X))\n",
    "X-= int(np.mean(X))\n",
    "X/= int(np.std(X))\n",
    "train_data = np.hstack((X,y_dash))\n",
    "train_data = train_data[:10,:]\n",
    "print(np.shape(train_data))\n",
    "\n",
    "\n",
    "np.random.shuffle(train_data)\n",
    "NUM_IMAGES = train_data.shape[0]\n",
    "\n",
    "filt1 = {}\n",
    "filt2 = {}\n",
    "bias1 = {}\n",
    "bias2 = {}\n",
    "for i in range(0,NUM_FILT1):\n",
    "    \n",
    "\tfilt1[i] = np.random.normal(loc = 0, scale = (1.0) * np.sqrt(1./(FILTER_SIZE*FILTER_SIZE*IMG_DEPTH)), size =   \t\t\t\t\t(IMG_DEPTH,FILTER_SIZE,FILTER_SIZE))\n",
    "\tbias1[i] = 0\n",
    "\t# v1[i] = 0\n",
    "\n",
    "for i in range(0,NUM_FILT2):\n",
    "\tfilt2[i] = filt1[i] = np.random.normal(loc = 0, scale = (1.0) * np.sqrt(1./(FILTER_SIZE*FILTER_SIZE*NUM_FILT2)), size = \t\t\t\t(NUM_FILT2,FILTER_SIZE,FILTER_SIZE))\n",
    "\tbias2[i] = 0\n",
    "\t# v2[i] = 0\n",
    "\n",
    "w1 = IMG_WIDTH-FILTER_SIZE+1\n",
    "w2 = w1-FILTER_SIZE+1\n",
    "theta3 = 0.01*np.random.rand(NUM_OUTPUT, (w2//2)*(w2//2)*NUM_FILT2)\n",
    "\n",
    "bias3 = np.zeros((NUM_OUTPUT,1))\n",
    "cost = []\n",
    "acc = []\n",
    "# pickle_in = open(PICKLE_FILE, 'rb')\n",
    "# out = pickle.load(pickle_in)\n",
    "\n",
    "# [filt1, filt2, bias1, bias2, theta3, bias3, cost, acc] = out\n",
    "\n",
    "\n",
    "print(\"Learning Rate:\"+str(LEARNING_RATE)+\", Batch Size:\"+str(BATCH_SIZE))\n",
    "\n",
    "\n",
    "##################performing convolution################\n",
    "\n",
    "\n",
    "(w, w) = train_data.shape\n",
    "l1 = len(filter1)\n",
    "l2 = len(filter2)\n",
    "( _, f, f) = filter1[0].shape\n",
    "w1 = w-f+1\n",
    "w2 = w1-f+1\n",
    "\n",
    "conv1 = np.zeros((l1,w1,w1))\n",
    "conv2 = np.zeros((l2,w2,w2))\n",
    "\n",
    "for jj in range(0,l1):\n",
    "    for x in range(0,w1):\n",
    "        for y in range(0,w1):\n",
    "            conv1[jj,x,y] = np.sum(image[:,x:x+f,y:y+f]*filter1[jj])+bias1[jj]\n",
    "conv1[conv1<=0] = 0 #relu activation\n",
    "\n",
    "\t## Calculating second Convolution layer\n",
    "for jj in range(0,l2):\n",
    "    for x in range(0,w2):\n",
    "        for y in range(0,w2):\n",
    "            conv2[jj,x,y] = np.sum(conv1[:,x:x+f,y:y+f]*filt2[jj])+bias2[jj]\n",
    "conv2[conv2<=0] = 0 # relu activation\n",
    "\n",
    "\t## Pooled layer with 2*2 size and stride 2,2\n",
    "pooled_layer = maxpool(conv2, 2, 2)\t\n",
    "\n",
    "fc1 = pooled_layer.reshape(((w2//2)*(w2//2)*l2,1))\n",
    "\n",
    "out = theta3.dot(fc1) + bias3\t#10*1\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
